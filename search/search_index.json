{"config":{"lang":["en"],"separator":"[\\s\\u200b\\-_,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Live-Streaming-Server-Net","text":"<p>Live-Streaming-Server-Net is a high-performance and flexible toolset which allows you to build your own live streaming server using .NET.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>RTMP/RTMPS protocol: Supports the RTMP and RTMPS protocols for streaming audio, video, and data.</li> <li>RTMP Relay: Supports relaying RTMP streams between servers, allowing building a scalable RTMP server cluster.</li> <li>RTMP Client: Provides a client library for connecting to RTMP servers and publishing/subscribing live streams.</li> <li>HTTP-FLV/WebSocket-FLV with ASP.NET CORE: Provides support for serving FLV live streams using HTTP-FLV and WebSocket-FLV protocols within an ASP.NET Core application.</li> <li>Transmuxing RTMP streams into HLS streams: Allows you to transmux RTMP streams into HLS (HTTP Live Streaming) streams using the built-in HLS transmuxer.</li> <li>Transcoding RTMP streams into Adaptive HLS streams: Integrates with FFmpeg to transcode RTMP streams into multiple-bitrate Adaptive HLS streams.</li> <li>Integration with FFmpeg: Provides support for processing the incoming RTMP stream with FFmpeg, for example, to create an MP4 archive.</li> <li>GOP caching: Supports caching the Group of Pictures (GOP) to ensure immediate availability of live streaming content.</li> <li>Custom authorization: Enables you to implement custom authorization mechanisms for accessing live streams.</li> <li>Admin panel: Includes an admin panel that provides an user interface for managing and monitoring the live streaming server.</li> <li>Cloud Storage Integration: Enabling real-time uploading of HLS files to cloud storage services like Azure Blob Storage, Google Cloud Storage, and AWS S3, which ensures scalable and efficient HLS stream distribution through CDN.</li> <li>Realtime HLS Subtitle Transcription: Integrates with Azure AI Speech to provide real-time transcription of HLS streams, automatically generating WebVTT subtitle files.</li> <li>Codecs: Supports AVC/H.264, HEVC/H.265, AAC, and MP3 codecs.</li> </ul>"},{"location":"#nuget-packages","title":"NuGet Packages","text":"Package Latest Version LiveStreamingServerNet LiveStreamingServerNet.Standalone LiveStreamingServerNet.AdminPanelUI LiveStreamingServerNet.Flv LiveStreamingServerNet.Networking LiveStreamingServerNet.Networking.Client LiveStreamingServerNet.Networking.Server LiveStreamingServerNet.Rtmp LiveStreamingServerNet.Rtmp.Client LiveStreamingServerNet.Rtmp.Relay LiveStreamingServerNet.Rtmp.Server LiveStreamingServerNet.StreamProcessor LiveStreamingServerNet.StreamProcessor.AmazonS3 LiveStreamingServerNet.StreamProcessor.AspNetCore LiveStreamingServerNet.StreamProcessor.AzureAISpeech LiveStreamingServerNet.StreamProcessor.AzureBlobStorage LiveStreamingServerNet.StreamProcessor.GoogleCloudStorage LiveStreamingServerNet.Utilities"},{"location":"#license","title":"License","text":"<p>This project is licensed under the terms of the MIT license.</p>"},{"location":"#acknowledgments","title":"Acknowledgments","text":"<p>Special thanks to JetBrains for providing the open-source software license that supports the development of this project.</p>"},{"location":"getting-started/","title":"Getting Started","text":"<p>LiveStreamingServerNet is a RTMP server framework that allows you to create your own live streaming server using .NET 7 or newer versions. It supports multiple platforms including Windows, Linux, and MacOS, and can be easily integrated into your projects as NuGet packages.</p>"},{"location":"getting-started/#setting-up-your-live-streaming-server","title":"Setting Up Your Live Streaming Server","text":"<p>This guide will walk you through the process of setting up your own live streaming server using LiveStreamingServerNet. By following these steps, you'll be able to create a server that can accept RTMP streams and broadcast them to viewers.</p>"},{"location":"getting-started/#step-1-initialize-a-new-project","title":"Step 1: Initialize a New Project","text":"<p>Create a new .NET console application using the following command:</p> <pre><code>dotnet new console\n</code></pre> <p>In this guide, we will use a basic console application as the foundation for the live streaming server. However, it is not mandatory, and you are free to run a live streaming server with an ASP.NET Core application as well.</p>"},{"location":"getting-started/#step-2-add-required-packages","title":"Step 2: Add Required Packages","text":"<p>Add the necessary packages to the created project with these commands:</p> <pre><code>dotnet add package LiveStreamingServerNet\ndotnet add package Microsoft.Extensions.Logging.Console\n</code></pre> <p>These commands will install the LiveStreamingServerNet package, which is the core library for building a live streaming server, as well as the Microsoft.Extensions.Logging.Console package, which allows you to log events to the console.</p>"},{"location":"getting-started/#step-3-configure-your-live-streaming-server","title":"Step 3: Configure Your Live Streaming Server","text":"<p>Edit <code>Program.cs</code> file to set up LiveStreamingServerNet:</p> <pre><code>using LiveStreamingServerNet;\nusing Microsoft.Extensions.Logging;\nusing System.Net;\n\nusing var server = LiveStreamingServerBuilder.Create()\n    .ConfigureLogging(options =&gt; options.AddConsole())\n    .Build();\n\nawait server.RunAsync(new IPEndPoint(IPAddress.Any, 1935));\n</code></pre> <p>This code sets up the server using LiveStreamingServerNet and configures it to log events to the console. It also specifies that the server should listen on port 1935 for RTMP streams.</p>"},{"location":"getting-started/#step-4-launch-your-live-streaming-server","title":"Step 4: Launch Your Live Streaming Server","text":"<p>Execute your live streaming server by running:</p> <pre><code>dotnet run\n</code></pre> <p>Now, your live streaming server should be running and ready to accept RTMP stream via 1935 port.</p>"},{"location":"getting-started/#interacting-with-your-live-streaming-server","title":"Interacting with your Live Streaming Server","text":"<p>With your live streaming server now up and running, you\u2019re all set to publish and play live streams.</p>"},{"location":"getting-started/#publish-a-live-stream","title":"Publish a Live Stream","text":"<p>You have the flexibility to publish your stream using a tool of your choice, such as OBS Studio or FFmpeg.</p> <p>With OBS Studio</p> <ol> <li>Open OBS Studio and go to \"Settings\".</li> <li>In the \"Settings\" window, select the \"Stream\" tab.</li> <li>Choose \"Custom\" as the \"Service\".</li> <li>Enter \"Server\": <code>rtmp://localhost:1935/live</code> and \"Stream Key\": <code>demo</code>.</li> <li>Click \"OK\" to save the settings.</li> <li>Click the \"Start Streaming\" button in OBS Studio to begin sending live stream to the RTMP server.</li> </ol> <p>With FFmpeg</p> <p>Assuming you have a media file at <code>input_file</code>, which could be in formats like mp4, wmv, etc. To publish it as a live stream using FFmpeg, execute the following command:</p> <pre><code>ffmpeg -re -i &lt;input_file&gt; -c:v libx264 -c:a aac -f flv rtmp://localhost:1935/live/demo\n</code></pre>"},{"location":"getting-started/#play-the-live-stream","title":"Play the Live Stream","text":"<p>Now, you can play the published live stream with your favorite tool.</p> <p>With VLC Media Player</p> <ol> <li>Open VLC Media Player.</li> <li>Go to the \"Media\" menu and select \"Open Network Stream\".</li> <li>In the \"Network\" tab, enter the URL: <code>rtmp://localhost:1935/live/demo</code>.</li> <li>Click the \"Play\" button to start playing the live stream.</li> </ol> <p>With FFplay</p> <p>Use the following command to play the live stream using FFplay</p> <pre><code>ffplay rtmp://localhost:1935/live/demo\n</code></pre>"},{"location":"kubernetes-integration/fleet/","title":"Live Streaming Server Fleet","text":"<p>This page is currently under construction.</p>"},{"location":"kubernetes-integration/introduction/","title":"Introduction","text":"<p>This page is currently under construction.</p>"},{"location":"kubernetes-integration/operator/","title":"Kubernetes Operator","text":"<p>This page is currently under construction.</p>"},{"location":"kubernetes-integration/pod/","title":"Kubernetes Pod","text":"<p>This page is currently under construction.</p>"},{"location":"performance-benchmark/","title":"Performance Benchmark","text":""},{"location":"performance-benchmark/#method","title":"Method","text":"<p>To conduct the performance benchmarking, all the applications are packaged as Docker images and deployed to Azure Container Instances with the configuration of <code>1 vCPU, 2 GiB memory, 0 GPUs</code>, running on Linux OS.</p> <p>To facilitate large-scale stream publishing and subscription, the srs-bench benchmarking tool is employed. Besides, all benchmark tests were performed with the same set of videos at different resolutions and bitrates, including <code>240P at 200 kbps</code>, <code>480P at 500 kbps</code>, and <code>720P at 1500 kbps</code>.</p>"},{"location":"performance-benchmark/#code","title":"Code","text":"<p>The following code sets up a live streaming server capable of:</p> <ol> <li>Accepting and broadcasting AVC/AAC RTMP streams.</li> <li>Transmuxing all the incoming RTMP streams into HLS streams with the built-in HLS transmuxer.</li> <li>Serving HLS streams via ASP.NET Core\u2019s static file middleware.</li> <li>Enabling GOP caching based on the <code>RTMP_ENABLE_GOP_CACHING</code> environment variable.</li> <li>Batching media packages within a <code>350ms</code> window to optimize performance for large-scale RTMP broadcasting.</li> <li>Providing an admin panel UI.</li> </ol> <pre><code>using LiveStreamingServerNet;\nusing LiveStreamingServerNet.AdminPanelUI;\nusing LiveStreamingServerNet.Rtmp;\nusing LiveStreamingServerNet.Standalone;\nusing LiveStreamingServerNet.Standalone.Installer;\nusing LiveStreamingServerNet.StreamProcessor.AspNetCore.Installer;\nusing LiveStreamingServerNet.StreamProcessor.Installer;\nusing System.Net;\n\nvar builder = WebApplication.CreateBuilder(args);\n\nbuilder.Services.AddLiveStreamingServer(\n    new IPEndPoint(IPAddress.Any, 1935),\n    serverConfig =&gt;\n    {\n        serverConfig.Configure(options =&gt;\n        {\n            options.EnableGopCaching = builder.Configuration.GetValue(\"RTMP_ENABLE_GOP_CACHING\", true);\n            options.MediaPacketBatchWindow = TimeSpan.FromMilliseconds(350);\n        });\n\n        serverConfig.AddVideoCodecFilter(builder =&gt; builder.Include(VideoCodec.AVC))\n                    .AddAudioCodecFilter(builder =&gt; builder.Include(AudioCodec.AAC));\n\n        serverConfig.AddStandaloneServices();\n\n        serverConfig.AddStreamProcessor()\n                    .AddHlsTransmuxer();\n    }\n);\n\nbuilder.Services.AddCors(options =&gt;\n    options.AddDefaultPolicy(policy =&gt;\n        policy.AllowAnyHeader()\n              .AllowAnyOrigin()\n              .AllowAnyMethod()\n    )\n);\n\nvar app = builder.Build();\n\napp.UseCors();\n\napp.UseHlsFiles();\n\napp.MapStandaloneServerApiEndPoints();\n\napp.UseAdminPanelUI();\n\nawait app.RunAsync();\n</code></pre>"},{"location":"performance-benchmark/#results","title":"Results","text":""},{"location":"performance-benchmark/#live-streaming-server-net","title":"Live-Streaming-Server-Net","text":""},{"location":"performance-benchmark/#150-publishers-streaming-rtmp-video-at-240p-and-200kbps","title":"150 Publishers Streaming RTMP Video at 240P and 200kbps","text":"CPU UsageMemory UsageNetwork Bytes Received"},{"location":"performance-benchmark/#300-publishers-streaming-rtmp-video-at-240p-and-200kbps","title":"300 Publishers Streaming RTMP Video at 240P and 200kbps","text":"CPU UsageMemory UsageNetwork Bytes Received"},{"location":"performance-benchmark/#150-publishers-streaming-rtmp-video-at-480p-and-500kbps","title":"150 Publishers Streaming RTMP Video at 480P and 500kbps","text":"CPU UsageMemory UsageNetwork Bytes Received"},{"location":"performance-benchmark/#100-publishers-streaming-rtmp-video-at-720p-and-1500kbps","title":"100 Publishers Streaming RTMP Video at 720P and 1500kbps","text":"CPU UsageMemory UsageNetwork Bytes Received"},{"location":"performance-benchmark/#1000-subscribers-receiving-rtmp-video-at-720p-and-1500kbps","title":"1000 Subscribers Receiving RTMP Video at 720P and 1500kbps","text":"CPU UsageMemory UsageNetwork Bytes ReceivedNetwork Bytes Transmitted"},{"location":"performance-benchmark/#live-streaming-server-net-with-gop-caching-disabled","title":"Live-Streaming-Server-Net with GOP caching disabled","text":"<p>Generally, if the stream is to be served as HLS, GOP caching, which consumes additional memory, is not necessary. Therefore, the benchmark tests are also conducted with GOP caching disabled.</p>"},{"location":"performance-benchmark/#150-publishers-streaming-rtmp-video-at-240p-and-200kbps_1","title":"150 Publishers Streaming RTMP Video at 240P and 200kbps","text":"CPU UsageMemory UsageNetwork Bytes Received"},{"location":"performance-benchmark/#300-publishers-streaming-rtmp-video-at-240p-and-200kbps_1","title":"300 Publishers Streaming RTMP Video at 240P and 200kbps","text":"CPU UsageMemory UsageNetwork Bytes Received"},{"location":"performance-benchmark/#150-publishers-streaming-rtmp-video-at-480p-and-500kbps_1","title":"150 Publishers Streaming RTMP Video at 480P and 500kbps","text":"CPU UsageMemory UsageNetwork Bytes Received"},{"location":"performance-benchmark/#100-publishers-streaming-rtmp-video-at-720p-and-1500kbps_1","title":"100 Publishers Streaming RTMP Video at 720P and 1500kbps","text":"CPU UsageMemory UsageNetwork Bytes Received"},{"location":"performance-benchmark/#200-publishers-streaming-rtmp-video-at-720p-and-1500kbps","title":"200 Publishers Streaming RTMP Video at 720P and 1500kbps","text":"CPU UsageMemory UsageNetwork Bytes Received"},{"location":"performance-benchmark/#300-publishers-streaming-rtmp-video-at-720p-and-1500kbps","title":"300 Publishers Streaming RTMP Video at 720P and 1500kbps","text":"CPU UsageMemory UsageNetwork Bytes Received"},{"location":"performance-benchmark/#400-publishers-streaming-rtmp-video-at-720p-and-1500kbps","title":"400 Publishers Streaming RTMP Video at 720P and 1500kbps","text":"CPU UsageMemory UsageNetwork Bytes Received"},{"location":"performance-benchmark/#srs-simple-realtime-server-5","title":"SRS (Simple Realtime Server) 5","text":"<p>As a reference, similar benchmark tests are performed on SRS 5.</p>"},{"location":"performance-benchmark/#150-publishers-streaming-rtmp-video-at-240p-and-200kbps_2","title":"150 Publishers Streaming RTMP Video at 240P and 200kbps","text":"CPU UsageMemory UsageNetwork Bytes Received"},{"location":"performance-benchmark/#150-publishers-streaming-rtmp-video-at-480p-and-500kbps_2","title":"150 Publishers Streaming RTMP Video at 480P and 500kbps","text":"CPU UsageMemory UsageNetwork Bytes Received"},{"location":"performance-benchmark/#100-publishers-streaming-rtmp-video-at-720p-and-1500kbps_2","title":"100 Publishers Streaming RTMP Video at 720P and 1500kbps","text":"CPU UsageMemory UsageNetwork Bytes Received"},{"location":"performance-benchmark/#1000-subscribers-receiving-rtmp-video-at-720p-and-1500kbps_1","title":"1000 Subscribers Receiving RTMP Video at 720P and 1500kbps","text":"CPU UsageMemory UsageNetwork Bytes ReceivedNetwork Bytes Transmitted"},{"location":"tutorials/adaptive-hls/","title":"Adaptive Bitrate HLS","text":"<p>To generate HLS streams at multiple bitrates, transcoding is required. Therefore, LiveStreamingServerNet integrates with FFmpeg to enable Adaptive Bitrate HLS Transcoding. However, it\u2019s important to note that transcoding is more resource-intensive compared to transmuxing.</p>"},{"location":"tutorials/adaptive-hls/#install-ffmpeg","title":"Install FFmpeg","text":"<p>To use the Adaptive HLS Transcoder, FFmpeg must be installed in advance.</p> <p>By default, the <code>FFmpeg</code> and <code>FFprobe</code> executables are located using the helper function <code>ExecutableFinder.FindExecutableFromPATH</code>, which first searches through all the directories defined in the <code>PATH</code> environment variable and then the current directory.</p>"},{"location":"tutorials/adaptive-hls/#adaptive-hls-transcoder","title":"Adaptive HLS Transcoder","text":"<p>Similar to the built-in HLS Transmuxer, the resulting HLS files can be served via ASP.NET Core and Cloud Storage Services. Please refer to the previous tutorials for the serving part. This section will focus on enabling the Adaptive HLS Transcoder.</p>"},{"location":"tutorials/adaptive-hls/#step-1-add-the-required-packages","title":"Step 1: Add the Required Packages","text":"<p>Add the necessary packages using the following commands:</p> <pre><code>dotnet add package LiveStreamingServerNet\ndotnet add package LiveStreamingServerNet.StreamProcessor\n</code></pre>"},{"location":"tutorials/adaptive-hls/#step-2-configure-your-live-streaming-server","title":"Step 2: Configure Your Live Streaming Server","text":"<pre><code>using LiveStreamingServerNet;\nusing LiveStreamingServerNet.StreamProcessor.FFmpeg.Contracts;\nusing LiveStreamingServerNet.StreamProcessor.Hls.Configurations;\nusing LiveStreamingServerNet.StreamProcessor.Installer;\nusing LiveStreamingServerNet.StreamProcessor.Utilities;\nusing Microsoft.Extensions.Logging;\nusing System.Net;\n\nvar outputDirectory = Path.Combine(Directory.GetCurrentDirectory(), \"output\");\n\nusing var liveStreamingServer = LiveStreamingServerBuilder.Create()\n    .ConfigureRtmpServer(options =&gt; options\n        .AddStreamProcessor()\n        .AddAdaptiveHlsTranscoder(config =&gt;\n        {\n            config.FFmpegPath = ExecutableFinder.FindExecutableFromPATH(\"ffmpeg\")!;\n            config.FFprobePath = ExecutableFinder.FindExecutableFromPATH(\"ffprobe\")!;\n            config.OutputPathResolver = new HlsOutputPathResolver(outputDirectory);\n\n            config.DownsamplingFilters = new DownsamplingFilter[]{\n                new DownsamplingFilter(\n                    Name: \"360p\",\n                    Height: 360,\n                    MaxVideoBitrate: \"600k\",\n                    MaxAudioBitrate: \"64k\"\n                ),\n\n                new DownsamplingFilter(\n                    Name: \"480p\",\n                    Height: 480,\n                    MaxVideoBitrate: \"1500k\",\n                    MaxAudioBitrate: \"128k\"\n                ),\n\n                new DownsamplingFilter(\n                    Name: \"720p\",\n                    Height: 720,\n                    MaxVideoBitrate: \"3000k\",\n                    MaxAudioBitrate: \"256k\"\n                )\n            };\n        })\n    )\n    .ConfigureLogging(options =&gt; options.AddConsole())\n    .Build();\n\nawait liveStreamingServer.RunAsync(new IPEndPoint(IPAddress.Any, 1935));\n\npublic class HlsOutputPathResolver : IFFmpegOutputPathResolver\n{\n    private readonly string _outputPath;\n\n    public HlsOutputPathResolver(string outputPath)\n    {\n        _outputPath = outputPath;\n    }\n\n    public ValueTask&lt;string&gt; ResolveOutputPath(IServiceProvider services, Guid contextIdentifier, string streamPath, IReadOnlyDictionary&lt;string, string&gt; streamArguments)\n    {\n        return ValueTask.FromResult(Path.Combine(_outputPath, streamPath.Trim('/'), \"output.m3u8\"));\n    }\n}\n</code></pre> <p>With this configuration, LiveStreamingServerNet will create an Adaptive HLS Transcoder whenever an RTMP stream is published to port 1935. The Adaptive HLS Transcoder will transcode the incoming stream into at most three streams with resolutions of 360p, 480p, and 720p, depending on the resolution of the incoming stream.</p>"},{"location":"tutorials/adaptive-hls/#step-3-launch-your-live-streaming-server","title":"Step 3: Launch Your Live Streaming Server","text":"<p>To execute your live streaming server, run the following command:</p> <pre><code>dotnet run\n</code></pre>"},{"location":"tutorials/adaptive-hls/#optimizing-the-performance","title":"Optimizing the Performance","text":""},{"location":"tutorials/adaptive-hls/#bypassing-audio-transcoding","title":"Bypassing Audio Transcoding","text":"<p>Transcoding demands significant computational resources. Therefore, bypassing audio transcoding can potentially lead to a reduction in resource utilization. However, this strategy requires that the incoming audio stream is encoded with AAC codec.</p> <pre><code>using LiveStreamingServerNet;\nusing LiveStreamingServerNet.Rtmp;\nusing LiveStreamingServerNet.StreamProcessor.Installer;\nusing Microsoft.Extensions.Logging;\nusing System.Net;\n\nusing var liveStreamingServer = LiveStreamingServerBuilder.Create()\n    .ConfigureRtmpServer(options =&gt; options\n        .AddAudioCodecFilter(builder =&gt; builder.Include(AudioCodec.AAC))\n        .AddStreamProcessor()\n        .AddAdaptiveHlsTranscoder(config =&gt;\n            config.AudioEncodingArguments = \"-c:a copy\"\n        )\n    )\n    .ConfigureLogging(options =&gt; options.AddConsole())\n    .Build();\n\nawait liveStreamingServer.RunAsync(new IPEndPoint(IPAddress.Any, 1935));\n</code></pre>"},{"location":"tutorials/adaptive-hls/#hardware-acceleration","title":"Hardware Acceleration","text":"<p>FFmpeg supports hardware acceleration. Please refer to HWAccelIntro for more details.</p> <p>For example</p> <pre><code>using LiveStreamingServerNet;\nusing LiveStreamingServerNet.Rtmp;\nusing LiveStreamingServerNet.StreamProcessor.Installer;\nusing Microsoft.Extensions.Logging;\nusing System.Net;\n\nusing var liveStreamingServer = LiveStreamingServerBuilder.Create()\n    .ConfigureRtmpServer(options =&gt; options\n        .AddVideoCodecFilter(builder =&gt; builder.Include(VideoCodec.AVC))\n        .AddStreamProcessor()\n        .AddAdaptiveHlsTranscoder(config =&gt;\n        {\n            config.VideoDecodingArguments = \"-hwaccel auto -c:v h264_cuvid\";\n            config.VideoEncodingArguments = \"-c:v h264_nvenc -g 30\";\n        })\n    )\n    .ConfigureLogging(options =&gt; options.AddConsole())\n    .Build();\n\nawait liveStreamingServer.RunAsync(new IPEndPoint(IPAddress.Any, 1935));\n</code></pre>"},{"location":"tutorials/admin-panel/","title":"Adding an Admin Panel","text":"<p>This guide will provide an explanation about adding an admin panel to the live streaming server. The admin panel allows you to browse the list of live streams, delete them, and preview the live streams via HTTP-FLV.</p>"},{"location":"tutorials/admin-panel/#step-1-initialize-a-new-project-and-add-required-packages","title":"Step 1: Initialize a New Project and Add Required Packages","text":"<p>An admin panel is served by a middleware of ASP.NET Core. Create an empty ASP.NET Core Web application and add the necessary packages using the following commands:</p> <pre><code>dotnet new web\ndotnet add package LiveStreamingServerNet\ndotnet add package LiveStreamingServerNet.AdminPanelUI\ndotnet add package LiveStreamingServerNet.Standalone\ndotnet add package LiveStreamingServerNet.Flv\n</code></pre> <p>The <code>LiveStreamingServerNet.AdminPanelUI</code> package is responsible for supplying the admin panel user interface. <code>The LiveStreamingServerNet.Standalone</code> package delivers the Web API endpoints that the admin panel UI utilizes. Meanwhile, the <code>LiveStreamingServerNet.Flv</code> package enables the HTTP-FLV preview functionality.</p>"},{"location":"tutorials/admin-panel/#step-2-configure-your-live-streaming-server","title":"Step 2: Configure Your Live Streaming Server","text":"<p>Edit <code>Program.cs</code> file:</p> <pre><code>using LiveStreamingServerNet;\nusing LiveStreamingServerNet.AdminPanelUI;\nusing LiveStreamingServerNet.Flv.Installer;\nusing LiveStreamingServerNet.Standalone;\nusing LiveStreamingServerNet.Standalone.Installer;\nusing System.Net;\n\nvar builder = WebApplication.CreateBuilder(args);\n\nbuilder.Services.AddLiveStreamingServer(\n    new IPEndPoint(IPAddress.Any, 1935),\n    options =&gt; options.AddStandaloneServices().AddFlv()\n);\n\nvar app = builder.Build();\n\napp.UseHttpFlv();\napp.MapStandaloneServerApiEndPoints();\napp.UseAdminPanelUI(new AdminPanelUIOptions { BasePath = \"/ui\", HasHttpFlvPreview = true });\n\napp.Run();\n</code></pre> <p>This code adds the live streaming server to the ASP.NET Core web app, while the live streaming server will run in the background using port 1935. In addition, the web app will serve both HTTP-FLV and the admin panel UI, as well as the API endpoints required by the admin panel.</p>"},{"location":"tutorials/admin-panel/#step-3-launch-your-live-streaming-server","title":"Step 3: Launch Your Live Streaming Server","text":"<p>Execute your live streaming server by running the following command:</p> <pre><code>dotnet run --urls=\"https://+:8080\"\n</code></pre> <p>Now, your live streaming server should be running and ready to accept RTMP streams via port 1935, and you can visit the admin panel at <code>https://localhost:8080/ui</code>.</p>"},{"location":"tutorials/admin-panel/#preview-of-the-admin-panel","title":"Preview of the Admin Panel","text":""},{"location":"tutorials/asp-net-core/","title":"Running with ASP.NET Core","text":"<p>LiveStreamingServerNet can run as a background service within an ASP.NET Core application.</p>"},{"location":"tutorials/asp-net-core/#step-1-initialize-a-new-project-and-add-required-packages","title":"Step 1: Initialize a New Project and Add Required Packages","text":"<p>Create an empty ASP.NET Core Web application and add the necessary packages using the following commands:</p> <pre><code>dotnet new web\ndotnet add package LiveStreamingServerNet\n</code></pre>"},{"location":"tutorials/asp-net-core/#step-2-configure-your-live-streaming-server","title":"Step 2: Configure Your Live Streaming Server","text":"<p>Edit <code>Program.cs</code> file:</p> <pre><code>using System.Net;\nusing LiveStreamingServerNet;\n\nvar builder = WebApplication.CreateBuilder(args);\n\nbuilder.Services.AddLiveStreamingServer(new IPEndPoint(IPAddress.Any, 1935));\n\nvar app = builder.Build();\n\nawait app.RunAsync();\n</code></pre> <p>This code adds the live streaming server to the ASP.NET Core web app, while the live streaming server will in the background using port 1935.</p>"},{"location":"tutorials/asp-net-core/#step-3-launch-your-live-streaming-server","title":"Step 3: Launch Your Live Streaming Server","text":"<p>Execute your live streaming server by running the following command:</p> <pre><code>dotnet run\n</code></pre>"},{"location":"tutorials/custom-authorization/","title":"Custom Authorization","text":"<p>To add authorization to stream publishing and subscribing, you can implement the <code>IAuthorizationHandler</code> interface. This allows you to provide your own custom authorization logic.</p> <p>In the following example, publishing will only be authorized when the publishing path includes a valid password parameter, i.e. <code>rtmp://127.0.0.1:1935/live/stream?password=123456</code>.</p>"},{"location":"tutorials/custom-authorization/#create-the-password-validator-service","title":"Create the Password Validator Service","text":"<pre><code>public interface IPasswordValidator\n{\n    ValueTask&lt;bool&gt; ValidatePassword(string password);\n}\n\npublic class DemoPasswordValidator : IPasswordValidator\n{\n    public ValueTask&lt;bool&gt; ValidatePassword(string password)\n    {\n        return ValueTask.FromResult(password == \"123456\");\n    }\n}\n</code></pre> <p>This <code>DemoPasswordValidator</code> is a simple example class to check if the password is 123456.</p>"},{"location":"tutorials/custom-authorization/#implement-the-iauthorizationhandler","title":"Implement the IAuthorizationHandler","text":"<pre><code>using LiveStreamingServerNet.Networking.Contracts;\nusing LiveStreamingServerNet.Rtmp.Server.Auth;\nusing LiveStreamingServerNet.Rtmp.Server.Auth.Contracts;\n\npublic class DemoAuthorizationHandler : IAuthorizationHandler\n{\n    private readonly IPasswordValidator _passwordValidator;\n\n    public DemoAuthorizationHandler(IPasswordValidator passwordValidator)\n    {\n        _passwordValidator = passwordValidator;\n    }\n\n    public async Task&lt;AuthorizationResult&gt; AuthorizePublishingAsync(\n        ISessionInfo client,\n        string streamPath,\n        IReadOnlyDictionary&lt;string, string&gt; streamArguments,\n        string publishingType)\n    {\n        if (streamArguments.TryGetValue(\"password\", out var password) &amp;&amp;\n            await _passwordValidator.ValidatePassword(password))\n            return AuthorizationResult.Authorized();\n\n        return AuthorizationResult.Unauthorized(\"incorrect password\");\n    }\n\n    public Task&lt;AuthorizationResult&gt; AuthorizeSubscribingAsync(\n        ISessionInfo client,\n        string streamPath,\n        IReadOnlyDictionary&lt;string, string&gt; streamArguments)\n    {\n        return Task.FromResult(AuthorizationResult.Authorized());\n    }\n}\n</code></pre> <p>This <code>DemoAuthorizationHandler</code> injects the IPasswordValidator in the constructor, extracts the <code>password</code> parameter, and passes it to <code>IPasswordValidator</code> for checking.</p>"},{"location":"tutorials/custom-authorization/#register-the-authorization-handler","title":"Register the Authorization Handler","text":"<pre><code>using LiveStreamingServerNet;\nusing LiveStreamingServerNet.Networking;\nusing Microsoft.Extensions.DependencyInjection;\nusing Microsoft.Extensions.Logging;\nusing System.Net;\n\nusing var liveStreamingServer = LiveStreamingServerBuilder.Create()\n    .ConfigureRtmpServer(options =&gt;\n    {\n        options.Services.AddSingleton&lt;IPasswordValidator, DemoPasswordValidator&gt;();\n        options.AddAuthorizationHandler&lt;DemoAuthorizationHandler&gt;();\n    })\n    .ConfigureLogging(options =&gt; options.AddConsole().SetMinimumLevel(LogLevel.Debug))\n    .Build();\n\nawait liveStreamingServer.RunAsync(new ServerEndPoint(new IPEndPoint(IPAddress.Any, 1935), false));\n</code></pre>"},{"location":"tutorials/custom-ffmpeg-process/","title":"Custom FFmpeg Process","text":"<p>This guide will provide an example to use FFmpeg to store the RTMP stream as an MP4 archive.</p>"},{"location":"tutorials/custom-ffmpeg-process/#add-the-required-packages","title":"Add the required packages","text":"<pre><code>dotnet add package LiveStreamingServerNet\ndotnet add package LiveStreamingServerNet.StreamProcessor\n</code></pre>"},{"location":"tutorials/custom-ffmpeg-process/#configure-your-live-streaming-server","title":"Configure Your Live Streaming Server","text":"<pre><code>using LiveStreamingServerNet;\nusing LiveStreamingServerNet.Networking;\nusing LiveStreamingServerNet.StreamProcessor.FFmpeg.Contracts;\nusing LiveStreamingServerNet.StreamProcessor.Installer;\nusing LiveStreamingServerNet.StreamProcessor.Utilities;\nusing Microsoft.Extensions.Logging;\nusing System.Net;\n\nusing var liveStreamingServer = LiveStreamingServerBuilder.Create()\n    .ConfigureRtmpServer(options =&gt; options\n        .AddStreamProcessor()\n        .AddFFmpeg(options =&gt;\n        {\n            options.Name = \"mp4-archive\";\n            options.FFmpegPath = ExecutableFinder.FindExecutableFromPATH(\"ffmpeg\")!;\n            options.FFmpegArguments = \"-i {inputPath} -c:v libx264 -c:a aac -preset ultrafast -f mp4 {outputPath}\";\n            options.OutputPathResolver = new Mp4OutputPathResolver(Path.Combine(Directory.GetCurrentDirectory(), \"mp4-archive\"));\n        })\n    )\n    .ConfigureLogging(options =&gt; options.AddConsole().SetMinimumLevel(LogLevel.Debug))\n    .Build();\n\nawait liveStreamingServer.RunAsync(new ServerEndPoint(new IPEndPoint(IPAddress.Any, 1935), false));\n\npublic class Mp4OutputPathResolver : IFFmpegOutputPathResolver\n{\n    private readonly string _outputDir;\n\n    public Mp4OutputPathResolver(string outputDir)\n    {\n        _outputDir = outputDir;\n    }\n\n    public ValueTask&lt;string&gt; ResolveOutputPath(IServiceProvider services, Guid contextIdentifier, string streamPath, IReadOnlyDictionary&lt;string, string&gt; streamArguments)\n    {\n        return ValueTask.FromResult(Path.Combine(_outputDir, streamPath.Trim('/'), \"output.mp4\"));\n    }\n}\n</code></pre> <p>Whenever a stream is published, a FFmpeg process with the argument <code>-i {inputPath} -c:v libx264 -c:a aac -preset ultrafast -f mp4 {outputPath}</code> will be automatically created. This process converts the RTMP stream to MP4.</p> <p>Note that <code>{inputPath}</code> and <code>{outputPath}</code> are placeholders which will be replaced by the actual paths internally.</p>"},{"location":"tutorials/dockerizing/","title":"Dockerizing the Application","text":""},{"location":"tutorials/dockerizing/#runtime-image","title":"Runtime Image","text":"<p>Some of the packages have dependencies on the ASP.NET Core framework, including:</p> <ul> <li>LiveStreamingServerNet.Standalone</li> <li>LiveStreamingServerNet.AdminPanelUI</li> <li>LiveStreamingServerNet.Flv</li> <li>LiveStreamingServerNet.StreamProcessor.AspNetCore</li> </ul> <p>Therefore when these packages are included in your application, or if your application depends on ASP.NET Core, please ensure that you use <code>mcr.microsoft.com/dotnet/aspnet:8.0</code> as the runtime image. Otherwise, you may choose to use <code>mcr.microsoft.com/dotnet/runtime:8.0</code> instead.</p>"},{"location":"tutorials/dockerizing/#ffmpeg-dependency","title":"FFmpeg Dependency","text":"<p>If your application requires FFmpeg, you can add the following command to install FFmpeg in the runtime image:</p> <pre><code>RUN apt-get update &amp;&amp; apt-get install -y ffmpeg\n</code></pre> <p>The FFmpeg binary can then be found with <code>ExecutableFinder.FindExecutableFromPATH(\"ffmpeg\")</code></p>"},{"location":"tutorials/dockerizing/#example-dockerfile","title":"Example Dockerfile","text":"<pre><code>FROM mcr.microsoft.com/dotnet/aspnet:8.0 AS base\nRUN apt-get update &amp;&amp; apt-get install -y ffmpeg\nEXPOSE 8080\nEXPOSE 1935\n\nFROM mcr.microsoft.com/dotnet/sdk:8.0 AS build\nWORKDIR /src\nCOPY your-project.csproj .\nRUN dotnet restore \"./your-project.csproj\"\nCOPY . .\nRUN dotnet build \"./your-project.csproj\" -c Release -o /app/build\n\nFROM build AS publish\nRUN dotnet publish \"./your-project.csproj\" -c Release -o /app/publish /p:UseAppHost=false\n\nFROM base AS final\nWORKDIR /app\nCOPY --from=publish /app/publish .\nENTRYPOINT [\"dotnet\", \"your-project.dll\"]\n</code></pre>"},{"location":"tutorials/hls-subtitle-transcription/","title":"HLS Subtitle Transcription","text":"<p>LiveStreamingServerNet enhances HLS streams with real-time subtitle transcription. By integrating with speech recognition services, it converts live audio into WebVTT subtitles delivered alongside your streams. Azure AI Speech Service integration is currently available, with support for additional providers planned.</p>"},{"location":"tutorials/hls-subtitle-transcription/#install-ffmpeg","title":"Install FFmpeg","text":"<p>To enable the HLS subtitle transcription, FFmpeg must be installed in advance to support transcoding the audio stream into the format that the speech recognition service accepts.</p> <p>By default, the <code>FFmpeg</code> and <code>FFprobe</code> executables are located using the helper function <code>ExecutableFinder.FindExecutableFromPATH</code>, which first searches through all the directories defined in the <code>PATH</code> environment variable and then the current directory.</p>"},{"location":"tutorials/hls-subtitle-transcription/#hls-subtitle-transcription_1","title":"HLS Subtitle Transcription","text":"<p>This section will guide you through setting up an HLS transmuxer to convert RTMP streams into HLS streams, enable HLS subtitle transcription for real-time subtitle generation, and serve these live HLS streams using ASP.NET Core.</p>"},{"location":"tutorials/hls-subtitle-transcription/#step-1-initialize-a-new-project-and-add-required-packages","title":"Step 1: Initialize a New Project and Add Required Packages","text":"<p>Create an empty ASP.NET Core Web application and add the necessary packages using the following commands:</p> <pre><code>dotnet new web\ndotnet add package LiveStreamingServerNet\ndotnet add package LiveStreamingServerNet.AdminPanelUI\ndotnet add package LiveStreamingServerNet.Standalone\ndotnet add package LiveStreamingServerNet.StreamProcessor\ndotnet add package LiveStreamingServerNet.StreamProcessor.AspNetCore\ndotnet add package LiveStreamingServerNet.StreamProcessor.AzureAISpeech\n</code></pre> <p>The packages <code>LiveStreamingServerNet.AdminPanelUI</code>, <code>LiveStreamingServerNet.Standalone</code> and <code>LiveStreamingServerNet.StreamProcessor.AspNetCore</code> are optional for launching the admin panel UI and serving HLS files for previewing the real-time subtitles.</p>"},{"location":"tutorials/hls-subtitle-transcription/#step-2-configure-your-live-streaming-server","title":"Step 2: Configure Your Live Streaming Server","text":"<p>Edit <code>Program.cs</code> file:</p> <pre><code>using LiveStreamingServerNet;\nusing LiveStreamingServerNet.AdminPanelUI;\nusing LiveStreamingServerNet.Rtmp;\nusing LiveStreamingServerNet.Standalone;\nusing LiveStreamingServerNet.Standalone.Installer;\nusing LiveStreamingServerNet.StreamProcessor.AspNetCore.Installer;\nusing LiveStreamingServerNet.StreamProcessor.AzureAISpeech.Installer;\nusing LiveStreamingServerNet.StreamProcessor.Hls.Subtitling;\nusing LiveStreamingServerNet.StreamProcessor.Installer;\nusing LiveStreamingServerNet.StreamProcessor.Utilities;\nusing Microsoft.CognitiveServices.Speech;\nusing System.Net;\n\nvar speechKey = Environment.GetEnvironmentVariable(\"AZURE_SPEECH_KEY\");\nvar speechRegion = Environment.GetEnvironmentVariable(\"AZURE_SPEECH_REGION\");\n\nvar builder = WebApplication.CreateBuilder(args);\n\nbuilder.Services.AddLiveStreamingServer(\n    new IPEndPoint(IPAddress.Any, 1935),\n    options =&gt; options\n        .AddStandaloneServices()\n        .Configure(options =&gt; options.EnableGopCaching = false)\n        .AddVideoCodecFilter(builder =&gt; builder.Include(VideoCodec.AVC).Include(VideoCodec.HEVC))\n        .AddAudioCodecFilter(builder =&gt; builder.Include(AudioCodec.AAC))\n        .AddStreamProcessor()\n        .AddHlsTransmuxer(options =&gt;\n        {\n            var subtitleTrackOptions = new SubtitleTrackOptions(\"Subtitle\");\n            var speechConfig = SpeechConfig.FromSubscription(speechKey, speechRegion);\n            var autoDetectLanguageConfig = AutoDetectSourceLanguageConfig.FromLanguages(new[] { \"en-US\", \"ja-JP\" });\n\n            options.AddAzureSpeechTranscription(subtitleTrackOptions, speechConfig, configure =&gt;\n                configure.WithFFmpegPath(ExecutableFinder.FindExecutableFromPATH(\"ffmpeg\")!)\n                         .WithAutoDetectLanguageConfig(autoDetectLanguageConfig)\n            );\n        })\n);\n\nvar app = builder.Build();\n\napp.UseHlsFiles();\napp.MapStandaloneServerApiEndPoints();\napp.UseAdminPanelUI(new AdminPanelUIOptions { BasePath = \"/ui\", HasHlsPreview = true });\n\napp.Run();\n</code></pre> <p>This code sets up the server using LiveStreamingServerNet to listen on port 1935 for RTMP streams. Whenever an RTMP stream is published to the server, a HLS transmuxer will be created to convert the RTMP stream into an HLS stream, also an Azure Speech subtitle transcriber will be created to transcribe the audio stream into a WebVTT subtitle stream.</p>"},{"location":"tutorials/hls-subtitle-transcription/#step-3-launch-your-live-streaming-server","title":"Step 3: Launch Your Live Streaming Server","text":"<p>Execute your live streaming server by running the following command:</p> <pre><code>dotnet run --urls=\"https://+:8080\"\n</code></pre> <p>Once your server is running, publish a live stream to the RTMP endpoint, for example, <code>rtmp://localhost:1935/live/demo</code>. The server will automatically convert the stream into HLS format and perform real-time subtitle transcription using Azure AI Speech Service. You can preview the HLS stream (with subtitles) via the Admin Panel UI available at <code>https://localhost:8080/ui</code>, or access the HLS stream directly by visiting <code>https://localhost:8080/live/demo/output.m3u8</code>.</p>"},{"location":"tutorials/rtmp-server-events/","title":"RTMP Server Events","text":"<p>There are multiple event handlers available, including <code>IRtmpServerConnectionEventHandler</code>, <code>IRtmpServerStreamEventHandler</code>, <code>IRtmpMediaMessageInterceptor</code> and <code>IRtmpMediaCachingInterceptor</code>, which are useful for extending the behavior of LiveStreamingServerNet.</p>"},{"location":"tutorials/rtmp-server-events/#interfaces","title":"Interfaces","text":"<p>Below are the interfaces for these event handlers:</p> <pre><code>public interface IRtmpServerConnectionEventHandler\n{\n    int GetOrder() =&gt; 0;\n    ValueTask OnRtmpClientCreatedAsync(IEventContext context, ISessionControl client);\n    ValueTask OnRtmpClientDisposingAsync(IEventContext context, uint clientId);\n    ValueTask OnRtmpClientDisposedAsync(IEventContext context, uint clientId);\n    ValueTask OnRtmpClientHandshakeCompleteAsync(IEventContext context, uint clientId);\n    ValueTask OnRtmpClientConnectedAsync(IEventContext context, uint clientId, IReadOnlyDictionary&lt;string, object&gt; commandObject, IReadOnlyDictionary&lt;string, object&gt;? arguments);\n}\n\npublic interface IRtmpServerStreamEventHandler\n{\n    int GetOrder() =&gt; 0;\n    ValueTask OnRtmpStreamPublishedAsync(IEventContext context, uint clientId, string streamPath, IReadOnlyDictionary&lt;string, string&gt; streamArguments);\n    ValueTask OnRtmpStreamUnpublishedAsync(IEventContext context, uint clientId, string streamPath);\n    ValueTask OnRtmpStreamSubscribedAsync(IEventContext context, uint clientId, string streamPath, IReadOnlyDictionary&lt;string, string&gt; streamArguments);\n    ValueTask OnRtmpStreamUnsubscribedAsync(IEventContext context, uint clientId, string streamPath);\n    ValueTask OnRtmpStreamMetaDataReceivedAsync(IEventContext context, uint clientId, string streamPath, IReadOnlyDictionary&lt;string, object&gt; metaData);\n}\n\npublic interface IRtmpMediaMessageInterceptor\n{\n    ValueTask OnReceiveMediaMessageAsync(uint clientId, string streamPath, MediaType mediaType, IRentedBuffer rentedBuffer, uint timestamp, bool isSkippable);\n}\n\npublic interface IRtmpMediaCachingInterceptor\n{\n    ValueTask OnCacheSequenceHeaderAsync(uint clientId, string streamPath, MediaType mediaType, byte[] sequenceHeader);\n    ValueTask OnCachePictureAsync(uint clientId, string streamPath, MediaType mediaType, IRentedBuffer rentedBuffer, uint timestamp);\n    ValueTask OnClearGroupOfPicturesCacheAsync(uint clientId, string streamPath);\n}\n</code></pre>"},{"location":"tutorials/rtmp-server-events/#usage-example","title":"Usage Example","text":"<p>For instance, if you want to limit the publishing time of every stream to a maximum of 30 minutes, you can do the following:</p>"},{"location":"tutorials/rtmp-server-events/#implement-irtmpserverstreameventhandler","title":"Implement IRtmpServerStreamEventHandler","text":"<pre><code>using LiveStreamingServerNet.Networking.Server.Contracts;\nusing LiveStreamingServerNet.Rtmp.Server.Contracts;\nusing LiveStreamingServerNet.Utilities.Contracts;\nusing Microsoft.Extensions.Options;\nusing System.Collections.Concurrent;\n\npublic class PublishingTimeLimiterConfig\n{\n    public int PublishingTimeLimitSeconds { get; set; }\n}\n\npublic class PublishingTimeLimiter : IRtmpServerStreamEventHandler, IDisposable\n{\n    private readonly ConcurrentDictionary&lt;uint, ITimer&gt; _clientTimers = new();\n    private readonly IServer _server;\n    private readonly PublishingTimeLimiterConfig _config;\n\n    public PublishingTimeLimiter(IServer server, IOptions&lt;PublishingTimeLimiterConfig&gt; config)\n    {\n        _server = server;\n        _config = config.Value;\n    }\n\n    public void Dispose()\n    {\n        foreach (var timer in _clientTimers.Values)\n            timer.Dispose();\n\n        _clientTimers.Clear();\n    }\n\n    public ValueTask OnRtmpStreamPublishedAsync(\n        IEventContext context, uint clientId, string streamPath, IReadOnlyDictionary&lt;string, string&gt; streamArguments)\n    {\n        _clientTimers[clientId] = new Timer(async _ =&gt;\n        {\n            var client = _server.GetClient(clientId);\n\n            if (client != null)\n                await client.DisconnectAsync();\n        }, null, TimeSpan.FromSeconds(_config.PublishingTimeLimitSeconds), Timeout.InfiniteTimeSpan);\n\n        return ValueTask.CompletedTask;\n    }\n\n    public ValueTask OnRtmpStreamUnpublishedAsync(IEventContext context, uint clientId, string streamPath)\n    {\n        if (_clientTimers.TryRemove(clientId, out var timer))\n            timer.Dispose();\n\n        return ValueTask.CompletedTask;\n    }\n\n    public ValueTask OnRtmpStreamMetaDataReceivedAsync(\n        IEventContext context, uint clientId, string streamPath, IReadOnlyDictionary&lt;string, object&gt; metaData)\n        =&gt; ValueTask.CompletedTask;\n\n    public ValueTask OnRtmpStreamSubscribedAsync(\n        IEventContext context, uint clientId, string streamPath, IReadOnlyDictionary&lt;string, string&gt; streamArguments)\n        =&gt; ValueTask.CompletedTask;\n\n    public ValueTask OnRtmpStreamUnsubscribedAsync(IEventContext context, uint clientId, string streamPath)\n        =&gt; ValueTask.CompletedTask;\n}\n</code></pre> <p>The PublishingTimeLimiter, which implements <code>IRtmpServerStreamEventHandler</code>, will create a timer to disconnect the client after <code>PublishingTimeLimitSeconds</code>, and dispose the corresponding timer when the stream is unpublished.</p>"},{"location":"tutorials/rtmp-server-events/#register-the-event-handler","title":"Register the Event Handler","text":"<pre><code>using LiveStreamingServerNet;\nusing LiveStreamingServerNet.Networking;\nusing Microsoft.Extensions.DependencyInjection;\nusing Microsoft.Extensions.Logging;\nusing System.Net;\n\nusing var liveStreamingServer = LiveStreamingServerBuilder.Create()\n    .ConfigureRtmpServer(options =&gt;\n    {\n        options.Services.Configure&lt;PublishingTimeLimiterConfig&gt;(config =&gt;\n            config.PublishingTimeLimitSeconds = 60 * 30\n        );\n\n        options.AddStreamEventHandler&lt;PublishingTimeLimiter&gt;();\n    })\n    .ConfigureLogging(options =&gt; options.AddConsole())\n    .Build();\n\nawait liveStreamingServer.RunAsync(new ServerEndPoint(new IPEndPoint(IPAddress.Any, 1935), false));\n</code></pre> <p>This code adds the implementation of <code>IRtmpServerStreamEventHandler</code> to the RTMP server.</p>"},{"location":"tutorials/rtmps/","title":"Securing Streams with RTMPS","text":"<p>Just as HTTP has its secure counterpart in HTTPS, RTMP also has a secure variant known as RTMPS. RTMPS enhances RTMP by incorporating an extra layer of security via TLS or SSL encryption, which is important to mitigate concerns related to piracy and cybersecurity threats.</p>"},{"location":"tutorials/rtmps/#step-1-initialize-a-new-project-and-add-required-packages","title":"Step 1: Initialize a New Project and Add Required Packages","text":"<pre><code>dotnet new console\ndotnet add package LiveStreamingServerNet\ndotnet add package Microsoft.Extensions.Logging.Console\n</code></pre> <p>As usual, it\u2019s not mandatory to use a Console Application as the foundation.</p>"},{"location":"tutorials/rtmps/#step-2-configure-your-live-streaming-server","title":"Step 2: Configure Your Live Streaming Server","text":"<p>LiveStreamingServerNet uses <code>System.Net.Security.SslStream</code> to internally encrypt the RTMP stream. Therefore, you need to provide a <code>X509Certificate2</code>.</p> <p>Assuming you have a PFX archive file, edit the <code>Program.cs</code> file:</p> <pre><code>using LiveStreamingServerNet;\nusing Microsoft.Extensions.Logging;\nusing System.Security.Cryptography.X509Certificates;\nusing System.Net;\nusing LiveStreamingServerNet.Networking;\n\nvar pfxPath = Environment.GetEnvironmentVariable(\"CERT_PFX_PATH\")!;\nvar pfxPassword = Environment.GetEnvironmentVariable(\"CERT_PFX_PASSWORD\")!;\n\nvar serverCertificate = new X509Certificate2(pfxPath, pfxPassword);\n\nvar liveStreamingServer = LiveStreamingServerBuilder.Create()\n    .ConfigureServer(options =&gt; options.ConfigureSecurity(options =&gt;\n        options.ServerCertificate = serverCertificate\n    ))\n    .ConfigureRtmpServer(options =&gt;\n        options.Configure(options =&gt; options.EnableGopCaching = true)\n    )\n    .ConfigureLogging(options =&gt; options.AddConsole().SetMinimumLevel(LogLevel.Debug))\n    .Build();\n\nawait liveStreamingServer.RunAsync(new ServerEndPoint(new IPEndPoint(IPAddress.Any, 443), IsSecure: true));\n</code></pre> <p>LiveStreamingServerNet also supports running the live streaming server on multiple ports. Therefore, it\u2019s possible to run the server with both the RTMP and RTMPS protocols simultaneously.</p> <pre><code>var endPoints = new List&lt;ServerEndPoint&gt; {\n    new ServerEndPoint(new IPEndPoint(IPAddress.Any, 1935), IsSecure: false),\n    new ServerEndPoint(new IPEndPoint(IPAddress.Any, 443), IsSecure: true)\n};\n\nawait liveStreamingServer.RunAsync(endPoints);\n</code></pre>"},{"location":"tutorials/rtmps/#step-3-launch-your-live-streaming-server","title":"Step 3: Launch Your Live Streaming Server","text":"<p>Execute your live streaming server by running:</p> <pre><code>dotnet run\n</code></pre> <p>Upon successful execution, your live streaming server will start running. It will be ready to accept RTMPS streams via port 443. For instance, you can test it by sending a stream to <code>rtmps://localhost/live/demo</code>.</p>"},{"location":"tutorials/serving-flv/","title":"Serving FLV Live Streams","text":"<p>This guide will introduce the way to serve live streams via HTTP-FLV and WebSocket-FLV.</p>"},{"location":"tutorials/serving-flv/#step-1-initialize-a-new-project-and-add-required-packages","title":"Step 1: Initialize a New Project and Add Required Packages","text":"<p>Both HTTP-FLV and WebSocket-FLV will be served via middlewares of ASP.NET Core. Create an empty ASP.NET Core Web application and add the necessary packages using the following commands:</p> <pre><code>dotnet new web\ndotnet add package LiveStreamingServerNet\ndotnet add package LiveStreamingServerNet.Flv\n</code></pre>"},{"location":"tutorials/serving-flv/#step-2-configure-your-live-streaming-server","title":"Step 2: Configure Your Live Streaming Server","text":"<p>Edit <code>Program.cs</code> file:</p> <pre><code>using System.Net;\nusing LiveStreamingServerNet;\nusing LiveStreamingServerNet.Flv.Installer;\n\nvar builder = WebApplication.CreateBuilder(args);\n\nbuilder.Services.AddLiveStreamingServer(\n    new IPEndPoint(IPAddress.Any, 1935),\n    options =&gt; options.AddFlv()\n);\n\nvar app = builder.Build();\n\napp.UseWebSockets();\n\napp.UseWebSocketFlv();\n\napp.UseHttpFlv();\n\nawait app.RunAsync();\n</code></pre> <p>This code sets up the live streaming server and the ASP.NET Core web app, while the live streaming server will run alongside the web app using port 1935. In addition, the web app will serve both HTTP-FLV and WebSocket-FLV.</p> <p>Note that <code>app.UseWebSockets()</code> must be added before <code>app.UseWebSocketFlv(liveStreamingServer)</code> to ensure a correct WebSocket pipeline.</p> <p>If CORS is required, you can add the CORS service and middleware as usual. For example:</p> <pre><code>using System.Net;\nusing LiveStreamingServerNet;\nusing LiveStreamingServerNet.Flv.Installer;\n\nvar builder = WebApplication.CreateBuilder(args);\n\nbuilder.Services.AddLiveStreamingServer(\n    new IPEndPoint(IPAddress.Any, 1935),\n    options =&gt; options.AddFlv()\n);\n\nbuilder.Services.AddCors(options =&gt;\n    options.AddDefaultPolicy(policy =&gt;\n        policy.AllowAnyHeader()\n              .AllowAnyOrigin()\n              .AllowAnyMethod()\n    )\n);\n\nvar app = builder.Build();\n\napp.UseWebSockets();\n\napp.UseWebSocketFlv();\n\napp.UseHttpFlv();\n\nawait app.RunAsync();\n</code></pre>"},{"location":"tutorials/serving-flv/#step-3-launch-your-live-streaming-server","title":"Step 3: Launch Your Live Streaming Server","text":"<p>Execute your live streaming server by running the following command:</p> <pre><code>dotnet run --urls=\"https://+:8080\"\n</code></pre> <p>Now, your live streaming server should be running and ready to accept RTMP streams via port 1935.</p> <p>Once a live stream is published to <code>rtmp://localhost:1935/live/demo</code>, you can visit the HTTP-FLV live stream at</p> <pre><code>https://localhost:8080/live/demo.flv\n</code></pre> <p>or WebSocket-FLV live stream at</p> <pre><code>wss://localhost:8080/live/demo.flv\n</code></pre>"},{"location":"tutorials/serving-hls-cloud-storage/","title":"Serving HLS Stream via Cloud Storage Service","text":"<p>The following will use Azure Blob Storage as an example.</p>"},{"location":"tutorials/serving-hls-cloud-storage/#step-1-initialize-a-new-project-and-add-the-required-packages","title":"Step 1: Initialize a New Project and Add the Required Packages","text":"<p>Create an empty console application and add the necessary packages using the following commands:</p> <pre><code>dotnet new console\ndotnet add package LiveStreamingServerNet\ndotnet add package LiveStreamingServerNet.StreamProcessor\ndotnet add package LiveStreamingServerNet.StreamProcessor.AzureBlobStorage\ndotnet add package Microsoft.Extensions.Logging.Console\n</code></pre>"},{"location":"tutorials/serving-hls-cloud-storage/#step-2-configure-your-live-streaming-server","title":"Step 2: Configure Your Live Streaming Server","text":"<p>Modify <code>Program.cs</code> file:</p> <pre><code>using Azure.Storage.Blobs;\nusing LiveStreamingServerNet;\nusing LiveStreamingServerNet.StreamProcessor;\nusing LiveStreamingServerNet.StreamProcessor.AzureBlobStorage.Installer;\nusing LiveStreamingServerNet.StreamProcessor.Hls;\nusing LiveStreamingServerNet.StreamProcessor.Hls.Contracts;\nusing LiveStreamingServerNet.StreamProcessor.Installer;\nusing LiveStreamingServerNet.Utilities.Contracts;\nusing Microsoft.Extensions.Logging;\nusing System.Net;\n\nvar outputDir = Path.Combine(Directory.GetCurrentDirectory(), \"output\");\nnew DirectoryInfo(outputDir).Create();\n\nvar blobContainerClient = new BlobContainerClient(\n    Environment.GetEnvironmentVariable(\"AZURE_BLOB_STORAGE_CONNECTION_STRING\"),\n    Environment.GetEnvironmentVariable(\"AZURE_BLOB_CONTAINER\"));\n\nusing var liveStreamingServer = LiveStreamingServerBuilder.Create()\n    .ConfigureRtmpServer(options =&gt; options\n        .AddStreamProcessor(options =&gt;\n        {\n            options.AddHlsUploader(uploaderOptions =&gt;\n            {\n                uploaderOptions.AddHlsStorageEventHandler&lt;HlsStorageEventListener&gt;();\n                uploaderOptions.AddAzureBlobStorage(blobContainerClient);\n            });\n        })\n        .AddHlsTransmuxer()\n    )\n    .ConfigureLogging(options =&gt; options.AddConsole())\n    .Build();\n\nawait liveStreamingServer.RunAsync(new IPEndPoint(IPAddress.Any, 1935));\n\npublic class HlsStorageEventListener : IHlsStorageEventHandler\n{\n    private readonly ILogger _logger;\n\n    public HlsStorageEventListener(ILogger&lt;HlsStorageEventListener&gt; logger)\n    {\n        _logger = logger;\n    }\n\n    public Task OnHlsFilesStoredAsync(\n        IEventContext eventContext,\n        StreamProcessingContext context,\n        bool initial,\n        IReadOnlyList&lt;StoredManifest&gt; storedManifests,\n        IReadOnlyList&lt;StoredSegment&gt; storedSegments)\n    {\n        if (!initial)\n            return Task.CompletedTask;\n\n        var mainManifestName = Path.GetFileName(context.OutputPath);\n        var mainManifest = storedManifests.FirstOrDefault(x =&gt; x.Name.Equals(mainManifestName));\n\n        if (mainManifest != default)\n            _logger.LogInformation($\"[{context.Identifier}] Main manifest {mainManifestName} stored at {mainManifest.Uri}\");\n\n        return Task.CompletedTask;\n    }\n\n    public Task OnHlsFilesStoringCompleteAsync(IEventContext eventContext, StreamProcessingContext context)\n    {\n        return Task.CompletedTask;\n    }\n}\n</code></pre> <p>This setup allows the server to receive RTMP streams, transmux them to HLS formats, and then upload the HLS files to Azure Blob Storage. Besides, the HlsStorageEventListener will log information about the stored files for monitoring purposes.</p>"},{"location":"tutorials/serving-hls-cloud-storage/#step-3-launch-your-live-streaming-server","title":"Step 3: Launch Your Live Streaming Server","text":"<p>To execute your live streaming server, run the following command:</p> <pre><code>dotnet run\n</code></pre> <p>Once a live stream is published to the live streaming server, the corresponding stream will be automatically uploaded to the Azure Blob Storage container.</p>"},{"location":"tutorials/serving-hls/","title":"Serving HLS Live Streams","text":"<p>LiveStreamingServerNet provides a seamless way to the transmux RTMP streams into HLS streams using the built-in HLS transmuxer, without the need for external tools like FFmpeg.</p>"},{"location":"tutorials/serving-hls/#quick-setup-guide-for-your-live-streaming-server","title":"Quick Setup Guide for Your Live Streaming Server","text":"<p>This section will guide you through adding a HLS transmuxer to convert RTMP streams into HLS streams and serving the HLS live streams with ASP.NET Core.</p>"},{"location":"tutorials/serving-hls/#step-1-initialize-a-new-project-and-add-required-packages","title":"Step 1: Initialize a New Project and Add Required Packages","text":"<p>Create an empty ASP.NET Core Web application and add the necessary packages using the following commands:</p> <pre><code>dotnet new web\ndotnet add package LiveStreamingServerNet\ndotnet add package LiveStreamingServerNet.StreamProcessor\ndotnet add package LiveStreamingServerNet.StreamProcessor.AspNetCore\n</code></pre>"},{"location":"tutorials/serving-hls/#step-2-configure-your-live-streaming-server","title":"Step 2: Configure Your Live Streaming Server","text":"<p>Edit <code>Program.cs</code> file:</p> <pre><code>using LiveStreamingServerNet;\nusing LiveStreamingServerNet.StreamProcessor.AspNetCore.Configurations;\nusing LiveStreamingServerNet.StreamProcessor.AspNetCore.Installer;\nusing LiveStreamingServerNet.StreamProcessor.Contracts;\nusing LiveStreamingServerNet.StreamProcessor.Hls.Contracts;\nusing LiveStreamingServerNet.StreamProcessor.Installer;\nusing LiveStreamingServerNet.Utilities.Contracts;\nusing System.Net;\n\nvar outputDir = Path.Combine(Directory.GetCurrentDirectory(), \"hls-output\");\nnew DirectoryInfo(outputDir).Create();\n\nvar builder = WebApplication.CreateBuilder(args);\n\nbuilder.Services.AddLiveStreamingServer(\n    new IPEndPoint(IPAddress.Any, 1935),\n    options =&gt; options\n        .AddStreamProcessor(options =&gt; options.AddStreamProcessorEventHandler&lt;HlsTransmuxerEventListener&gt;())\n        .AddHlsTransmuxer(options.Configure(config =&gt;\n            config.OutputPathResolver = new HlsTransmuxerOutputPathResolver(outputDir)\n        ))\n);\n\nvar app = builder.Build();\n\napp.UseHlsFiles(new HlsServingOptions\n{\n    Root = outputDir,\n    RequestPath = \"/hls\"\n});\n\napp.Run();\n\npublic class HlsTransmuxerOutputPathResolver : IHlsOutputPathResolver\n{\n    private readonly string _outputDir;\n\n    public HlsTransmuxerOutputPathResolver(string outputDir)\n    {\n        _outputDir = outputDir;\n    }\n\n    public ValueTask&lt;string&gt; ResolveOutputPath(IServiceProvider services, Guid contextIdentifier, string streamPath, IReadOnlyDictionary&lt;string, string&gt; streamArguments)\n    {\n        return ValueTask.FromResult(Path.Combine(_outputDir, contextIdentifier.ToString(), \"output.m3u8\"));\n    }\n}\n\npublic class HlsTransmuxerEventListener : IStreamProcessorEventHandler\n{\n    private readonly ILogger _logger;\n\n    public HlsTransmuxerEventListener(ILogger&lt;HlsTransmuxerEventListener&gt; logger)\n    {\n        _logger = logger;\n    }\n\n    public Task OnStreamProcessorStartedAsync(IEventContext context, string transmuxer, Guid identifier, uint clientId, string inputPath, string outputPath, string streamPath, IReadOnlyDictionary&lt;string, string&gt; streamArguments)\n    {\n        _logger.LogInformation($\"[{identifier}] Transmuxer {transmuxer} started: {inputPath} -&gt; {outputPath}\");\n        return Task.CompletedTask;\n    }\n\n    public Task OnStreamProcessorStoppedAsync(IEventContext context, string transmuxer, Guid identifier, uint clientId, string inputPath, string outputPath, string streamPath, IReadOnlyDictionary&lt;string, string&gt; streamArguments)\n    {\n        _logger.LogInformation($\"[{identifier}] Transmuxer {transmuxer} stopped: {inputPath} -&gt; {outputPath}\");\n        return Task.CompletedTask;\n    }\n}\n</code></pre> <p>This code sets up the server using LiveStreamingServerNet to listen on port 1935 for RTMP streams. Whenever an RTMP stream is published to the server, a HLS transmuxer will be created to convert the RTMP stream into an HLS stream, and its manifest will be stored as <code>/hls-output/{streamPath}/output.m3u8</code>. Additionally, the <code>HlsTransmuxerEventListener</code> is added to log out the transmuxer events. And finally, the <code>HlsFilesMiddleware</code> is added to serve the generated HLS live streams at <code>/hls/**</code>.</p>"},{"location":"tutorials/serving-hls/#step-3-launch-your-live-streaming-server","title":"Step 3: Launch Your Live Streaming Server","text":"<p>Execute your live streaming server by running the following command:</p> <pre><code>dotnet run --urls=\"https://+:8080\"\n</code></pre> <p>Now, when you publish a live stream to <code>rtmp://localhost:1935/live/demo</code>, the HLS transmuxer will automatically convert it into HLS format. You can access the HLS stream by visiting <code>https://localhost:8080/hls/live/demo/output.m3u8</code>. If you need to play the HLS stream in a browser, you generally need a JavaScript library such as hls.js or video.js.</p>"},{"location":"tutorials/serving-hls/#filtering-video-and-audio-codecs","title":"Filtering Video and Audio Codecs","text":"<p>The HLS transmuxer doesn't transcode the RTMP streams but only changes the container format from RTMP to HLS, which uses the MPEG-TS format for its media segments. This process doesn't alter the actual video or audio data and is significantly less resource-intensive compared to transcoding.</p> <p>Therefore, to ensure that transmuxing works as expected, it\u2019s necessary to verify that the incoming RTMP stream contains elementary streams with the H.264 and AAC codecs.</p> <p>You can add the video and codec filters like this:</p> <pre><code>var liveStreamingServer = LiveStreamingServerBuilder.Create()\n    .ConfigureRtmpServer(options =&gt; options\n        .AddVideoCodecFilter(builder =&gt; builder.Include(VideoCodec.AVC).Include(VideoCodec.HEVC))\n        .AddAudioCodecFilter(builder =&gt; builder.Include(AudioCodec.AAC))\n        .AddStreamProcessor()\n        .AddHlsTransmuxer()\n    )\n    .Build();\n</code></pre>"},{"location":"tutorials/serving-hls/#enabling-hls-transmuxer-conditionally","title":"Enabling HLS Transmuxer Conditionally","text":"<p>Sometimes, not all the RTMP streams require transmuxing into HLS streams. In such cases, you can provide an <code>IStreamProcessorCondition</code> to the <code>HlsTransmuxerConfiguration</code> in order to selectively enable the HLS Transmuxer.</p> <p>For Example, you can implement an <code>IStreamProcessorCondition</code> like this:</p> <pre><code>public class HlsTransmuxingCondition : IStreamProcessorCondition\n{\n    public ValueTask&lt;bool&gt; IsEnabled(IServiceProvider services, string streamPath, IReadOnlyDictionary&lt;string, string&gt; streamArguments)\n    {\n        return ValueTask.FromResult(streamArguments.GetValueOrDefault(\"hls\", \"false\") == \"true\");\n    }\n}\n</code></pre> <p>And add it to the <code>HlsTransmuxerConfiguration</code>:</p> <pre><code>var liveStreamingServer = LiveStreamingServerBuilder.Create()\n    .ConfigureRtmpServer(options =&gt; options\n        .AddStreamProcessor()\n        .AddHlsTransmuxer(options =&gt; options.Configure(config =&gt;\n            config.Condition = new HlsTransmuxingCondition()\n        ))\n    )\n    .Build();\n</code></pre> <p>Now, only RTMP streams published with argument <code>hls=true</code> (e.g. <code>rtmp://localhost:1935/live/demo?hls=true</code>) will be transmuxed into HLS streams.</p>"}]}